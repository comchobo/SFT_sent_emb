{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow4PYVtkJ86n"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentence_transformers evaluate peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow4PYVtkJ86n"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "from sentence_transformers.models import Transformer\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import torch\n",
        "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType, PeftModelForFeatureExtraction\n",
        "from utils import preprocess_nli, preprocess_sts\n",
        "import copy, os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNjc2YJPSGUo"
      },
      "source": [
        "**You guys need to install torch library, depending on which environment you use.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzk_7PC6LwUH"
      },
      "outputs": [],
      "source": [
        "debug = True # define debug mode \n",
        "model_and_paths = 'klue/roberta-large'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Since the average length of target data is 33 and std is 12, I set `max_length` to cover 2~3 sigma, hence set as 64**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txp9q1O1LzzW"
      },
      "outputs": [],
      "source": [
        "max_len = 64\n",
        "train_epochs = 5 if debug==False else 1\n",
        "batch_size = 16\n",
        "dataloader_num_workers= 2 if debug==False else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWHKTTnyL1UQ"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "import json\n",
        "from typing import List, Dict, Optional\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrhMIkDKSMEj"
      },
      "source": [
        "**Following class is for setting any torch.nn module to be self.model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWhPGPwUL4X1"
      },
      "outputs": [],
      "source": [
        "class Customized_Transformer(Transformer):\n",
        "    def __init__(self, model_name_or_path: str, max_seq_length: int = 64,\n",
        "                 model_args: Dict = {}, cache_dir: Optional[str] = None,\n",
        "                 tokenizer_args: Dict = {}):\n",
        "        super(Customized_Transformer, self).__init__(model_name_or_path)\n",
        "        self.config_keys = ['max_seq_length']\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "        config = AutoConfig.from_pretrained(model_name_or_path, **model_args, cache_dir=cache_dir)\n",
        "        self.auto_model = AutoModel.from_pretrained(model_name_or_path, config=config, cache_dir=cache_dir)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, cache_dir=cache_dir, **tokenizer_args)\n",
        "\n",
        "    def tokenize(self, texts):\n",
        "        output = {}\n",
        "        if isinstance(texts[0], str):\n",
        "            to_tokenize = [texts]\n",
        "        elif isinstance(texts[0], dict):\n",
        "            to_tokenize = []\n",
        "            output[\"text_keys\"] = []\n",
        "            for lookup in texts:\n",
        "                text_key, text = next(iter(lookup.items()))\n",
        "                to_tokenize.append(text)\n",
        "                output[\"text_keys\"].append(text_key)\n",
        "            to_tokenize = [to_tokenize]\n",
        "        else:\n",
        "            batch1, batch2 = [], []\n",
        "            for text_tuple in texts:\n",
        "                batch1.append(text_tuple[0])\n",
        "                batch2.append(text_tuple[1])\n",
        "            to_tokenize = [batch1, batch2]\n",
        "\n",
        "        # strip\n",
        "        to_tokenize = [[str(s).strip() for s in col] for col in to_tokenize]\n",
        "\n",
        "        # Lowercase\n",
        "        if self.do_lower_case:\n",
        "            to_tokenize = [[s.lower() for s in col] for col in to_tokenize]\n",
        "\n",
        "        output.update(\n",
        "            self.tokenizer(\n",
        "                *to_tokenize,\n",
        "                padding='max_length',\n",
        "                truncation=\"longest_first\",\n",
        "                return_tensors=\"pt\",\n",
        "                max_length=self.max_seq_length,\n",
        "            )\n",
        "        )\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIzH-4UXSf_b"
      },
      "source": [
        "**set model**\n",
        "\n",
        "* You can set device here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF65sFtJL5AO"
      },
      "outputs": [],
      "source": [
        "def set_sent_tranformer(model_and_paths):\n",
        "    emb_model = Customized_Transformer(model_and_paths, max_seq_length = 64)\n",
        "    pooling_model = models.Pooling(emb_model.get_word_embedding_dimension(),\n",
        "                                   pooling_mode='mean')\n",
        "    sent_rep_model = SentenceTransformer(modules=[emb_model, pooling_model], device='cpu')\n",
        "    return sent_rep_model\n",
        "\n",
        "sent_rep_model = set_sent_tranformer(model_and_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8_K_V5cTbfA"
      },
      "source": [
        "**Following code will erase garbage memories.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTEoRkKBTazY"
      },
      "outputs": [],
      "source": [
        "def del_whole(SentenceTransformer_model):\n",
        "    del SentenceTransformer_model\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiNReI_TSrYH"
      },
      "source": [
        "`preprocess_nli` or `sts` will set each dataset to be ready for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odAoenuAL7nu"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from utils import preprocess_nli, preprocess_sts\n",
        "\n",
        "nli_dataset = load_dataset('klue', 'nli')\n",
        "sts_dataset = load_dataset('klue', 'sts')\n",
        "\n",
        "train_nli, valid_nli = preprocess_nli(nli_dataset)\n",
        "train_sts, valid_sts = preprocess_sts(sts_dataset)\n",
        "\n",
        "if debug:\n",
        "    train_nli = train_nli[:500]\n",
        "    train_sts = train_sts[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7roK9gnmS7iU"
      },
      "source": [
        "**Finally, set dataloader and ...**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu2t7_s4L_IY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader_nli = DataLoader(train_nli, shuffle=True, batch_size=batch_size,\n",
        "                                  num_workers=dataloader_num_workers)\n",
        "train_dataloader_sts = DataLoader(train_sts, shuffle=True, batch_size=batch_size,\n",
        "                                  num_workers=dataloader_num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZBJuQIBS6Wf"
      },
      "outputs": [],
      "source": [
        "from CustomizedESEv import customizedEmbeddingSimilarityEvaluator\n",
        "evaluator = customizedEmbeddingSimilarityEvaluator.from_input_examples(valid_sts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMh69dAkTAQx"
      },
      "source": [
        "**launch!**\n",
        "\n",
        "**Following code will find best learning rate.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z0O-3mIMCzs"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.losses import MultipleNegativesRankingLoss, CosineSimilarityLoss, TripletLoss\n",
        "from sentence_transformers.losses import AnglELoss\n",
        "lr_finder = [{'lr':5e-5},{'lr':2e-5},{'lr':9e-6}]\n",
        "\n",
        "for lr_suggestion in lr_finder:\n",
        "    copied_sent_rep_model = sent_rep_model\n",
        "\n",
        "    train_loss_nli = MultipleNegativesRankingLoss(model=copied_sent_rep_model)\n",
        "    train_loss_sts = AnglELoss(model=copied_sent_rep_model)\n",
        "\n",
        "    train_objectives = [(train_dataloader_nli, train_loss_nli), (train_dataloader_sts, train_loss_sts)]\n",
        "\n",
        "    copied_sent_rep_model.fit(\n",
        "        train_objectives=train_objectives, optimizer_params=lr_suggestion,\n",
        "        epochs=train_epochs, output_path=f'MeanMulti_test_large_{lr_suggestion[\"lr\"]}_maxlen',\n",
        "        warmup_steps=50, evaluator=evaluator)\n",
        "\n",
        "    print(f'Best score of klue_large_longer_{lr_suggestion[\"lr\"]} : {copied_sent_rep_model.best_score}')\n",
        "    del_whole(copied_sent_rep_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMc-eCgNRqa4"
      },
      "source": [
        "**Test phase. I used KorSTS to test OOD performance.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggyXkqyuRljE"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from sentence_transformers.readers import InputExample\n",
        "import os\n",
        "\n",
        "def load_kor_sts_samples(filename):\n",
        "    samples = []\n",
        "    with open(filename, 'rt', encoding='utf8') as fIn:\n",
        "        reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
        "        for row in reader:\n",
        "            score = float(row['score']) #/ 5.0  Normalize score to range 0 ... 1\n",
        "            samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
        "    return samples\n",
        "\n",
        "sts_dataset_path = 'KorNLUDatasets/KorSTS'\n",
        "test_file = os.path.join(sts_dataset_path, \"sts-test.tsv\")\n",
        "test_samples = load_kor_sts_samples(test_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnw77QytR1ks"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(modules=[Transformer(model_path,max_seq_length=64),\n",
        "                                       Pooling(word_embedding_dimension=1024, pooling_mode='mean')])\n",
        "# test_evaluator=evaluator\n",
        "test_evaluator = customizedEmbeddingSimilarityEvaluator.from_input_examples(test_samples)\n",
        "\n",
        "try:\n",
        "    os.mkdir(res_path)\n",
        "except FileExistsError:\n",
        "    pass\n",
        "\n",
        "print(test_evaluator(model, output_path=res_path))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
